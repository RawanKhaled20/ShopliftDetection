{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7723023,
          "sourceType": "datasetVersion",
          "datasetId": 4511562
        },
        {
          "sourceId": 7723202,
          "sourceType": "datasetVersion",
          "datasetId": 4511683
        },
        {
          "sourceId": 7729079,
          "sourceType": "datasetVersion",
          "datasetId": 4516100
        },
        {
          "sourceId": 7729268,
          "sourceType": "datasetVersion",
          "datasetId": 4516245
        },
        {
          "sourceId": 7738014,
          "sourceType": "datasetVersion",
          "datasetId": 4522506
        },
        {
          "sourceId": 7738018,
          "sourceType": "datasetVersion",
          "datasetId": 4522509
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2 # for capturing videos\n",
        "\n",
        "import math # for mathematical operations\n",
        "\n",
        "import matplotlib.pyplot as plt # for plotting the images\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from keras.preprocessing import image # for preprocessing the images\n",
        "\n",
        "import numpy as np # for mathematical operations\n",
        "\n",
        "from skimage.transform import resize # for resizing images\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-01T14:06:22.195366Z",
          "iopub.execute_input": "2024-03-01T14:06:22.195700Z",
          "iopub.status.idle": "2024-03-01T14:06:38.287295Z",
          "shell.execute_reply.started": "2024-03-01T14:06:22.195672Z",
          "shell.execute_reply": "2024-03-01T14:06:38.286476Z"
        },
        "trusted": true,
        "id": "ZWCAShFm7zeP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory where the frame images are saved\n",
        "frame_images_directory = '/content'\n",
        "\n",
        "# Function to delete all files in a directory\n",
        "def delete_files_in_directory(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)  # Delete the file\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {file_path}: {e}\")\n",
        "\n",
        "# Delete all files in the frame images directory\n",
        "delete_files_in_directory(frame_images_directory)"
      ],
      "metadata": {
        "id": "n82AJjAS9-6S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def clear_folder(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
        "\n",
        "# Specify the folder path to be cleared\n",
        "folder_to_clear = '/content/dcsass dataset'\n",
        "\n",
        "# Call the function to clear the folder\n",
        "clear_folder(folder_to_clear)"
      ],
      "metadata": {
        "id": "xg7a3qp73F3p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "37e-RV6u709r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "cQ4NkEri73AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "metadata": {
        "id": "1-EB7UHS74kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "C46uRR4S76S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rawankhaled20/shoplifting-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfQHK68m78WI",
        "outputId": "a5c2704e-024c-4c1d-ec51-3f9b538e04e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading shoplifting-data.zip to /content\n",
            " 94% 329M/352M [00:03<00:00, 87.7MB/s]\n",
            "100% 352M/352M [00:03<00:00, 112MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rawankhaled20/notshoplifting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X9pt9br8tuo",
        "outputId": "3194d79a-2ac7-4096-b267-de37080da7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading notshoplifting.zip to /content\n",
            " 94% 341M/362M [00:03<00:00, 79.3MB/s]\n",
            "100% 362M/362M [00:03<00:00, 112MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mateohervas/dcsass-dataset"
      ],
      "metadata": {
        "id": "5bx90rbPpH06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa40544-8e30-48ce-f8b4-54f6eb4b25e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading dcsass-dataset.zip to /content\n",
            " 99% 1.34G/1.35G [00:13<00:00, 128MB/s]\n",
            "100% 1.35G/1.35G [00:14<00:00, 104MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dcsass-dataset.zip"
      ],
      "metadata": {
        "id": "GbVz6ICEpJs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Define the name of the folder you want to create\n",
        "folder_name = 'Shoplifting'\n",
        "\n",
        "# Define the path where you want to create the folder\n",
        "folder_path = '/content/' + folder_name\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    print(f\"Folder '{folder_name}' created successfully at '{folder_path}'\")\n",
        "else:\n",
        "    print(f\"Folder '{folder_name}' already exists at '{folder_path}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aVyK4Rz8MrB",
        "outputId": "6d2d56ab-cfe6-40b2-cf43-c33ca93c3de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'Shoplifting' created successfully at '/content/Shoplifting'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Define the path to the zipped file\n",
        "zip_file_path = '/content/notshoplifting.zip'\n",
        "\n",
        "# Define the path to the destination folder\n",
        "destination_folder_path = '/content/NotShoplifting1'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder_path, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zipped file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_folder_path)\n",
        "\n",
        "# List the extracted files\n",
        "extracted_files = zip_ref.namelist()\n",
        "\n",
        "# Move the video files to the destination folder\n",
        "for file_name in extracted_files:\n",
        "    if file_name.endswith('.mp4'):  # Check if the file is a video file\n",
        "        source_file_path = os.path.join(destination_folder_path, file_name)\n",
        "        destination_file_path = os.path.join(destination_folder_path, file_name.split('/')[-1])  # Extract the file name\n",
        "        os.rename(source_file_path, destination_file_path)\n"
      ],
      "metadata": {
        "id": "nt_rJBx67-Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the paths to the folders\n",
        "shoplift_folder = \"/content/Shoplifting1\"\n",
        "noshoplift_folder = \"/content/NotShoplifting1\"\n",
        "\n",
        "# Get the list of video files in each folder\n",
        "shoplift_videos = [os.path.join(shoplift_folder, filename) for filename in os.listdir(shoplift_folder)]\n",
        "noshoplift_videos = [os.path.join(noshoplift_folder, filename) for filename in os.listdir(noshoplift_folder)]\n",
        "\n",
        "# Combine the lists of video files\n",
        "all_videos = shoplift_videos + noshoplift_videos\n",
        "\n",
        "# Create a DataFrame\n",
        "train = pd.DataFrame({'video_name': all_videos})\n",
        "\n",
        "print(train.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:06:38.288749Z",
          "iopub.execute_input": "2024-03-01T14:06:38.289278Z",
          "iopub.status.idle": "2024-03-01T14:06:38.400245Z",
          "shell.execute_reply.started": "2024-03-01T14:06:38.289253Z",
          "shell.execute_reply": "2024-03-01T14:06:38.399350Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL83r36c7zeQ",
        "outputId": "40596fdd-31d4-49ac-8aff-acc1c2173af1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 video_name\n",
            "0  /content/Shoplifting1/shop_lifter_90.mp4\n",
            "1   /content/Shoplifting1/shop_lifter_0.mp4\n",
            "2  /content/Shoplifting1/shop_lifter_78.mp4\n",
            "3  /content/Shoplifting1/shop_lifter_69.mp4\n",
            "4  /content/Shoplifting1/shop_lifter_81.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_video_tag = []\n",
        "\n",
        "for i in range(train.shape[0]):\n",
        "    train_video_tag.append(train['video_name'][i].split('/')[0])\n",
        "\n",
        "train['tag'] = train_video_tag"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:06:38.401396Z",
          "iopub.execute_input": "2024-03-01T14:06:38.401758Z",
          "iopub.status.idle": "2024-03-01T14:06:38.412575Z",
          "shell.execute_reply.started": "2024-03-01T14:06:38.401722Z",
          "shell.execute_reply": "2024-03-01T14:06:38.411692Z"
        },
        "trusted": true,
        "id": "FfilK1ib7zeR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def store_frames_from_folder(folder_path, destination_folder):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        video_file = os.path.join(folder_path, filename)\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
        "        count = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            if count % math.floor(frame_rate) == 0:\n",
        "                frame_filename = f\"{filename.split('.')[0]}_frame{count}.jpg\"\n",
        "                destination_path = os.path.join(destination_folder, frame_filename)\n",
        "                cv2.imwrite(destination_path, frame)\n",
        "            count += 1\n",
        "        cap.release()\n",
        "\n",
        "# Define the path to the train folder where frames will be stored\n",
        "train_folder = '/content/Train1'\n",
        "\n",
        "# Create the train folder if it doesn't exist\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "\n",
        "# Store frames from both shoplift and not shoplift folders into train folder\n",
        "store_frames_from_folder(shoplift_folder, train_folder)\n",
        "store_frames_from_folder(noshoplift_folder, train_folder)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:06:38.414584Z",
          "iopub.execute_input": "2024-03-01T14:06:38.414844Z",
          "iopub.status.idle": "2024-03-01T14:08:08.957762Z",
          "shell.execute_reply.started": "2024-03-01T14:06:38.414822Z",
          "shell.execute_reply": "2024-03-01T14:08:08.956665Z"
        },
        "trusted": true,
        "id": "HvT_uXSq7zeR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the names of all the images\n",
        "images = glob(\"/content/Train1/*.jpg\")  # Search for all .jpg files in the current directory\n",
        "\n",
        "train_image = []\n",
        "train_class = []\n",
        "\n",
        "for i in tqdm(range(len(images))):\n",
        "    # Creating the image name\n",
        "    train_image.append(images[i])\n",
        "\n",
        "    # Creating the class of image\n",
        "    class_label_parts = images[i].split('_')\n",
        "    class_label = class_label_parts[2]\n",
        "    if class_label == 'n':\n",
        "            train_class.append(0)\n",
        "    else:\n",
        "            train_class.append(1)\n",
        "\n",
        "# Storing the images and their class in a DataFrame\n",
        "train_data = pd.DataFrame()\n",
        "train_data['image'] = train_image\n",
        "train_data['class'] = train_class\n",
        "\n",
        "\n",
        "# Converting the DataFrame into a CSV file\n",
        "train_data.to_csv('train_new.csv', header=True, index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:08:08.959748Z",
          "iopub.execute_input": "2024-03-01T14:08:08.960082Z",
          "iopub.status.idle": "2024-03-01T14:08:09.004226Z",
          "shell.execute_reply.started": "2024-03-01T14:08:08.960047Z",
          "shell.execute_reply": "2024-03-01T14:08:09.003309Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuKRMecF7zeR",
        "outputId": "9944ab90-3671-4496-9678-2f5e70bfe9c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3766/3766 [00:00<00:00, 689319.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:08:09.005553Z",
          "iopub.execute_input": "2024-03-01T14:08:09.005901Z",
          "iopub.status.idle": "2024-03-01T14:08:09.011844Z",
          "shell.execute_reply.started": "2024-03-01T14:08:09.005869Z",
          "shell.execute_reply": "2024-03-01T14:08:09.010967Z"
        },
        "trusted": true,
        "id": "TKXzYx_87zeR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_new.csv')\n",
        "\n",
        "train.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:08:09.013217Z",
          "iopub.execute_input": "2024-03-01T14:08:09.013539Z",
          "iopub.status.idle": "2024-03-01T14:08:09.037448Z",
          "shell.execute_reply.started": "2024-03-01T14:08:09.013508Z",
          "shell.execute_reply": "2024-03-01T14:08:09.036621Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bucvuXL07zeR",
        "outputId": "9265d198-96d5-41ea-d929-0800f0ccd34a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           image  class\n",
              "0   /content/Train1/shop_lifter_103_frame200.jpg      1\n",
              "1  /content/Train1/shop_lifter_n_80_frame350.jpg      0\n",
              "2    /content/Train1/shop_lifter_41_frame144.jpg      1\n",
              "3    /content/Train1/shop_lifter_63_frame144.jpg      1\n",
              "4  /content/Train1/shop_lifter_n_79_frame175.jpg      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d21985f3-2b57-482c-9fa0-76a395cdcab3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/Train1/shop_lifter_103_frame200.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/Train1/shop_lifter_n_80_frame350.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/Train1/shop_lifter_41_frame144.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/Train1/shop_lifter_63_frame144.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/Train1/shop_lifter_n_79_frame175.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d21985f3-2b57-482c-9fa0-76a395cdcab3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d21985f3-2b57-482c-9fa0-76a395cdcab3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d21985f3-2b57-482c-9fa0-76a395cdcab3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f06894c-607e-4af0-aea1-9a129ab5c347\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f06894c-607e-4af0-aea1-9a129ab5c347')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f06894c-607e-4af0-aea1-9a129ab5c347 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 3766,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3766,\n        \"samples\": [\n          \"/content/Train1/shop_lifter_n_14_frame350.jpg\",\n          \"/content/Train1/shop_lifter_38_frame144.jpg\",\n          \"/content/Train1/shop_lifter_10_frame96.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an empty list\n",
        "\n",
        "train_image = []\n",
        "\n",
        "# for loop to read and store frames\n",
        "\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "\n",
        "      # loading the image and keeping the target size as (224,224,3)\n",
        "\n",
        "    img = image.load_img(train['image'][i], target_size=(224,224,3))\n",
        "\n",
        "     # converting it to array\n",
        "\n",
        "    img = image.img_to_array(img)\n",
        "\n",
        "     # normalizing the pixel value\n",
        "\n",
        "    img = img/255\n",
        "\n",
        "    # appending the image to the train_image list\n",
        "\n",
        "    train_image.append(img)\n",
        "\n",
        "# converting the list to numpy array\n",
        "\n",
        "X = np.array(train_image)\n",
        "\n",
        "# shape of the array\n",
        "\n",
        "X.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:08:09.038522Z",
          "iopub.execute_input": "2024-03-01T14:08:09.038783Z",
          "iopub.status.idle": "2024-03-01T14:08:23.650129Z",
          "shell.execute_reply.started": "2024-03-01T14:08:09.038761Z",
          "shell.execute_reply": "2024-03-01T14:08:23.649150Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5ar2Jbc7zeR",
        "outputId": "e7cc550b-51df-4de3-a0df-0d64bc1775f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3766/3766 [00:20<00:00, 186.93it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3766, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the target\n",
        "\n",
        "y = train['class']\n",
        "\n",
        "# creating the training and validation set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:54:04.798552Z",
          "iopub.execute_input": "2024-03-01T14:54:04.799363Z",
          "iopub.status.idle": "2024-03-01T14:54:05.440867Z",
          "shell.execute_reply.started": "2024-03-01T14:54:04.799330Z",
          "shell.execute_reply": "2024-03-01T14:54:05.439822Z"
        },
        "trusted": true,
        "id": "WfUoetTR7zeS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:53:58.257893Z",
          "iopub.execute_input": "2024-03-01T14:53:58.258292Z",
          "iopub.status.idle": "2024-03-01T14:53:58.516265Z",
          "shell.execute_reply.started": "2024-03-01T14:53:58.258257Z",
          "shell.execute_reply": "2024-03-01T14:53:58.515479Z"
        },
        "trusted": true,
        "id": "T4PxJl8L7zeS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=0.1,  # Randomly zoom images by 10%\n",
        "    fill_mode='nearest'  # Fill any missing pixels after rotation or shifting\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator to X_train\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Define the number of augmented samples per original sample\n",
        "num_augmented_samples = 1\n",
        "\n",
        "# Generate augmented samples\n",
        "augmented_data_generator = datagen.flow(X_train, batch_size=num_augmented_samples)\n",
        "\n",
        "# Generate augmented samples and append them to X_train_augmented\n",
        "X_train_augmented = []\n",
        "for _ in tqdm(range(X_train.shape[0])):\n",
        "    batch = augmented_data_generator.next()\n",
        "    X_train_augmented.extend(batch)\n",
        "\n",
        "# Convert the list of augmented samples to a numpy array\n",
        "X_train_augmented = np.array(X_train_augmented)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP4KMyqj1nUg",
        "outputId": "1fa141b3-e793-420d-d238-39384e87564b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3012/3012 [00:32<00:00, 91.73it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=0.1,  # Randomly zoom images by 10%\n",
        "    fill_mode='nearest'  # Fill any missing pixels after rotation or shifting\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator to X_train\n",
        "datagen.fit(X_test)\n",
        "\n",
        "# Define the number of augmented samples per original sample\n",
        "num_augmented_samples = 1\n",
        "\n",
        "# Generate augmented samples\n",
        "augmented_data_generator = datagen.flow(X_test, batch_size=num_augmented_samples)\n",
        "\n",
        "# Generate augmented samples and append them to X_train_augmented\n",
        "X_test_augmented = []\n",
        "for _ in tqdm(range(X_test.shape[0])):\n",
        "    batch = augmented_data_generator.next()\n",
        "    X_test_augmented.extend(batch)\n",
        "\n",
        "# Convert the list of augmented samples to a numpy array\n",
        "X_test_augmented = np.array(X_test_augmented)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9nvDs4p2AoH",
        "outputId": "f3c5438e-c5a2-444d-b8f0-5969d97c2d0f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 754/754 [00:12<00:00, 62.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate augmented samples with original X_train\n",
        "X_train_augmented = np.concatenate((X_train, X_train_augmented), axis=0)"
      ],
      "metadata": {
        "id": "NfvR5-en18Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate augmented samples with original X_test\n",
        "X_test_augmented = np.concatenate((X_test, X_test_augmented), axis=0)"
      ],
      "metadata": {
        "id": "ZV2mkd3W2O7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features for training frames\n",
        "\n",
        "X_train = base_model.predict(X_train)\n",
        "print(X_train.shape)\n",
        "# extracting features for validation frames\n",
        "\n",
        "X_test = base_model.predict(X_test)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:54:54.381881Z",
          "iopub.execute_input": "2024-03-01T14:54:54.382256Z",
          "iopub.status.idle": "2024-03-01T14:56:01.424398Z",
          "shell.execute_reply.started": "2024-03-01T14:54:54.382224Z",
          "shell.execute_reply": "2024-03-01T14:56:01.423329Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQfTjqpB7zeS",
        "outputId": "28edfe42-2985-4795-cd51-c4ba31e1c5c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 25s 179ms/step\n",
            "(3004, 7, 7, 512)\n",
            "24/24 [==============================] - 6s 279ms/step\n",
            "(751, 7, 7, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping the training as well as validation frames in single dimension\n",
        "\n",
        "X_train = X_train.reshape(3004, 7*7*512)\n",
        "X_test = X_test.reshape(751, 7*7*512)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:56:06.131005Z",
          "iopub.execute_input": "2024-03-01T14:56:06.131364Z",
          "iopub.status.idle": "2024-03-01T14:56:06.136313Z",
          "shell.execute_reply.started": "2024-03-01T14:56:06.131336Z",
          "shell.execute_reply": "2024-03-01T14:56:06.135088Z"
        },
        "trusted": true,
        "id": "TRRkI1Do7zeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:56:08.925771Z",
          "iopub.execute_input": "2024-03-01T14:56:08.926873Z",
          "iopub.status.idle": "2024-03-01T14:56:09.043154Z",
          "shell.execute_reply.started": "2024-03-01T14:56:08.926835Z",
          "shell.execute_reply": "2024-03-01T14:56:09.042318Z"
        },
        "trusted": true,
        "id": "07uqHnY37zeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of images\n",
        "\n",
        "X_train.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T14:56:13.813662Z",
          "iopub.execute_input": "2024-03-01T14:56:13.814022Z",
          "iopub.status.idle": "2024-03-01T14:56:13.819947Z",
          "shell.execute_reply.started": "2024-03-01T14:56:13.813991Z",
          "shell.execute_reply": "2024-03-01T14:56:13.819002Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M3-yo7b7zeS",
        "outputId": "b2e30a1a-24dd-4610-d0ef-bbbbd320e167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3004, 25088)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, Reshape\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Initial Dense layer with output shape (4*4*64,)\n",
        "model.add(Dense(4*4*64, activation='elu', input_shape=(25088,))) # Adjusted output shape\n",
        "\n",
        "# Dropout for regularization\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Reshape for Conv2D input\n",
        "model.add(Reshape((4, 4, 64)))  # Reshape to match output shape of previous layers\n",
        "\n",
        "# Convolutional layers for spatial feature extraction\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "# Flatten layer to prepare for LSTM\n",
        "model.add(Flatten()) # Adjusted to match Reshape layer input shape\n",
        "\n",
        "# Reshape for LSTM input\n",
        "model.add(Reshape((4, 128)))  # Reshape to match output shape of previous layers\n",
        "\n",
        "# LSTM layers for capturing temporal dependencies\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "\n",
        "# Additional dense layers with dropout\n",
        "model.add(Dense(128, activation='elu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T15:01:21.680190Z",
          "iopub.execute_input": "2024-03-01T15:01:21.681145Z",
          "iopub.status.idle": "2024-03-01T15:01:21.796828Z",
          "shell.execute_reply.started": "2024-03-01T15:01:21.681102Z",
          "shell.execute_reply": "2024-03-01T15:01:21.795964Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o81HqvAT7zeS",
        "outputId": "beae2c37-c48e-4b28-8961-41ada7156289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_29 (Dense)            (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " reshape_17 (Reshape)        (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 2, 2, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 1, 1, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 1, 1, 512)         1180160   \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " reshape_18 (Reshape)        (None, 4, 128)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 4, 128)            131584    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27437953 (104.67 MB)\n",
            "Trainable params: 27437953 (104.67 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=32, verbose=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T15:01:31.000891Z",
          "iopub.execute_input": "2024-03-01T15:01:31.001814Z",
          "iopub.status.idle": "2024-03-01T15:01:59.921474Z",
          "shell.execute_reply.started": "2024-03-01T15:01:31.001778Z",
          "shell.execute_reply": "2024-03-01T15:01:59.920647Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxJigFZG7zeS",
        "outputId": "01e70d99-0252-4c3a-f952-c40e2f971cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "94/94 [==============================] - 16s 33ms/step - loss: 0.6940 - accuracy: 0.4990 - val_loss: 0.6933 - val_accuracy: 0.5047\n",
            "Epoch 2/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.4831 - accuracy: 0.7217 - val_loss: 0.0934 - val_accuracy: 0.9534\n",
            "Epoch 3/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.0810 - accuracy: 0.9690 - val_loss: 0.0069 - val_accuracy: 0.9987\n",
            "Epoch 4/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.0180 - val_accuracy: 0.9933\n",
            "Epoch 5/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.0635 - accuracy: 0.9774 - val_loss: 3.4057e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 3.3919e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "94/94 [==============================] - 2s 24ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 5.0901e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.2609 - accuracy: 0.9264 - val_loss: 4.2123e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 11/20\n",
            "94/94 [==============================] - 2s 18ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 8.9753e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0621e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "94/94 [==============================] - 2s 20ms/step - loss: 1.1129e-04 - accuracy: 1.0000 - val_loss: 1.9188e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "94/94 [==============================] - 2s 25ms/step - loss: 7.9160e-05 - accuracy: 1.0000 - val_loss: 1.2241e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "94/94 [==============================] - 2s 18ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 8.7559e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 3.1927e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "94/94 [==============================] - 2s 18ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 2.7862e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 1.8890e-04 - accuracy: 1.0000 - val_loss: 5.8494e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "94/94 [==============================] - 2s 17ms/step - loss: 1.1697e-04 - accuracy: 1.0000 - val_loss: 2.3437e-06 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e5efc06c6a0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "preds = (preds >= 0.5).astype(np.int32)\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "df_cm = pd.DataFrame(cm, index=[0, 1], columns=['Notshoplift', 'Shoplift'])\n",
        "plt.subplot(121)\n",
        "plt.title(\"Confusion matrix\\n\")\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.xlabel(\"Actual\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T15:02:05.456854Z",
          "iopub.execute_input": "2024-03-01T15:02:05.457254Z",
          "iopub.status.idle": "2024-03-01T15:02:06.581040Z",
          "shell.execute_reply.started": "2024-03-01T15:02:05.457221Z",
          "shell.execute_reply": "2024-03-01T15:02:06.580240Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "Bq__9y6O7zeT",
        "outputId": "64477d7d-a72b-457f-ad6d-92445d045d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 25.722222222222214, 'Actual')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHrCAYAAAAzPLxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHZ0lEQVR4nO3de3zO9f/H8ee1tV3G7BqbbXwxIWxyKMIo5DSGUnPMYSRSozKn5uvb0GFRUvoWHYREBzkUFTFMZY7lkLKQrLKD42YOY9vn90c/17erjba5uPj0uP9un9tt1/vz/rw/r8/V96rX7/V+fz4fi2EYhgAAAEzCzdUBAAAAOBPJDQAAMBWSGwAAYCokNwAAwFRIbgAAgKmQ3AAAAFMhuQEAAKZCcgMAAEyF5AYAAJgKyQ1wHdm3b586dOggm80mi8WiZcuWOXX8X375RRaLRXPnznXquGZQrVo1DRw40NVhAHACkhvgLw4cOKCHH35Y1atXV6lSpeTj46MWLVrolVde0dmzZ6/quaOiorR79249++yzmj9/vho3bnxVz2dGP/zwgyZOnKhffvnF1aEAcBEL75YC/uezzz5Tjx49ZLVaNWDAAN166606f/68vv76ay1evFgDBw7Um2++eVXOffbsWZUuXVr//ve/9cwzz1yVcxiGoZycHHl4eMjd3f2qnMPVPv74Y/Xo0UPr1q1T69ati3xcTk6O3Nzc5OHhcfWCA3BN3OTqAIDrxcGDB9W7d28FBwdr7dq1qlixon1fdHS09u/fr88+++yqnf/IkSOSJF9f36t2DovFolKlSl218W80hmHo3Llz8vLyktVqdXU4AJyEaSng/02dOlXZ2dmaPXu2Q2JzUc2aNfX444/bP+fm5urpp59WjRo1ZLVaVa1aNY0fP145OTkOx1WrVk1dunTR119/rSZNmqhUqVKqXr263n33XXufiRMnKjg4WJI0ZswYWSwWVatWTZI0cOBA+99/NnHiRFksFoe21atX684775Svr6+8vb1Vu3ZtjR8/3r7/Umtu1q5dq7vuuktlypSRr6+v7r33Xv3444+Fnm///v0aOHCgfH19ZbPZNGjQIJ05c+bSX+z/a926tW699Vbt2rVLrVq1UunSpVWzZk19/PHHkqTExEQ1bdpUXl5eql27ttasWeNw/KFDh/Too4+qdu3a8vLykp+fn3r06OEw/TR37lz16NFDknT33XfLYrHIYrFo/fr1kv73z2LVqlVq3LixvLy89MYbb9j3XVxzYxiG7r77blWoUEEZGRn28c+fP6969eqpRo0aOn369N9eMwDXILkB/t/y5ctVvXp1NW/evEj9H3roIT311FO6/fbbNX36dLVq1Urx8fHq3bt3gb779+9X9+7d1b59e02bNk3lypXTwIEDtWfPHknS/fffr+nTp0uS+vTpo/nz5+vll18uVvx79uxRly5dlJOTo8mTJ2vatGm655579M0331z2uDVr1ig8PFwZGRmaOHGiYmJitHHjRrVo0aLQdSs9e/bUqVOnFB8fr549e2ru3LmaNGlSkWI8ceKEunTpoqZNm2rq1KmyWq3q3bu3PvzwQ/Xu3VsRERF6/vnndfr0aXXv3l2nTp2yH7t161Zt3LhRvXv31owZMzRs2DAlJCSodevW9uSqZcuWeuyxxyRJ48eP1/z58zV//nyFhITYx0lOTlafPn3Uvn17vfLKK2rYsGGBOC0Wi9555x2dO3dOw4YNs7fHxcVpz549mjNnjsqUKVOkawbgAgYAIzMz05Bk3HvvvUXqv2PHDkOS8dBDDzm0jx492pBkrF271t4WHBxsSDI2bNhgb8vIyDCsVqsxatQoe9vBgwcNScYLL7zgMGZUVJQRHBxcIIa4uDjjzz/h6dOnG5KMI0eOXDLui+eYM2eOva1hw4ZGQECAcezYMXvbzp07DTc3N2PAgAEFzvfggw86jHnfffcZfn5+lzznRa1atTIkGQsXLrS37d2715BkuLm5GZs2bbK3r1q1qkCcZ86cKTBmUlKSIcl499137W2LFi0yJBnr1q0r0P/iP4uVK1cWui8qKsqh7Y033jAkGe+9956xadMmw93d3XjiiSf+9loBuBaVG0BSVlaWJKls2bJF6v/5559LkmJiYhzaR40aJUkF1uaEhobqrrvusn+uUKGCateurZ9//rnEMf/VxbU6n3zyifLz84t0TGpqqnbs2KGBAweqfPny9vb69eurffv29uv8sz9XMiTprrvu0rFjx+zf4eV4e3s7VLZq164tX19fhYSEqGnTpvb2i3//+fvx8vKy/33hwgUdO3ZMNWvWlK+vr7799tsiXO0fbr75ZoWHhxep79ChQxUeHq4RI0aof//+qlGjhp577rkinwuAa5DcAJJ8fHwkyWEa5HIOHTokNzc31axZ06E9KChIvr6+OnTokEN71apVC4xRrlw5nThxooQRF9SrVy+1aNFCDz30kAIDA9W7d2999NFHl010LsZZu3btAvtCQkJ09OjRAmtL/not5cqVk6QiXUvlypULrBOy2WyqUqVKgba/jnn27Fk99dRTqlKliqxWq/z9/VWhQgWdPHlSmZmZf3vui26++eYi95Wk2bNn68yZM9q3b5/mzp3rkGQBuD6R3AD6I7mpVKmSvv/++2Id99f/UF/KpW67NorwJIZLnSMvL8/hs5eXlzZs2KA1a9aof//+2rVrl3r16qX27dsX6HslruRaLnVsUcYcMWKEnn32WfXs2VMfffSRvvzyS61evVp+fn5FrlRJKnZysn79evsi8d27dxfrWACuQXID/L8uXbrowIEDSkpK+tu+wcHBys/P1759+xza09PTdfLkSfudT85Qrlw5nTx5skD7X6tDkuTm5qa2bdvqpZde0g8//KBnn31Wa9eu1bp16wod+2KcycnJBfbt3btX/v7+183C2Y8//lhRUVGaNm2afXH2nXfeWeC7KWrCWRSpqakaMWKEOnTooC5dumj06NGFfu8Ari8kN8D/Gzt2rMqUKaOHHnpI6enpBfYfOHBAr7zyiiQpIiJCkgrc0fTSSy9Jkjp37uy0uGrUqKHMzEzt2rXL3paamqqlS5c69Dt+/HiBYy/eCfTX29Mvqlixoho2bKh58+Y5JAnff/+9vvzyS/t1Xg/c3d0LVIdeffXVAlWpi8lYYQlhcQ0ZMkT5+fmaPXu23nzzTd10000aPHhwkapUAFyHh/gB/69GjRpauHChevXqpZCQEIcnFG/cuFGLFi2yPwelQYMGioqK0ptvvqmTJ0+qVatW2rJli+bNm6du3brp7rvvdlpcvXv31rhx43Tffffpscce05kzZzRz5kzVqlXLYSHt5MmTtWHDBnXu3FnBwcHKyMjQ66+/rsqVK+vOO++85PgvvPCCOnXqpLCwMA0ePFhnz57Vq6++KpvNpokTJzrtOq5Uly5dNH/+fNlsNoWGhiopKUlr1qyRn5+fQ7+GDRvK3d1dU6ZMUWZmpqxWq9q0aaOAgIBinW/OnDn67LPPNHfuXFWuXFnSH8lUv379NHPmTD366KNOuzYAzkVyA/zJPffco127dumFF17QJ598opkzZ8pqtap+/fqaNm2ahgwZYu/79ttvq3r16po7d66WLl2qoKAgxcbGKi4uzqkx+fn5aenSpYqJidHYsWN18803Kz4+Xvv27XNIbu655x798ssveuedd3T06FH5+/urVatWmjRpkn2BbmHatWunlStXKi4uTk899ZQ8PDzUqlUrTZkypdiLb6+mV155Re7u7lqwYIHOnTunFi1a2J/R82dBQUGaNWuW4uPjNXjwYOXl5WndunXFSm5+++03jRw5Ul27dlVUVJS9vW/fvlq8eLHGjh2rTp06XVffD4D/4d1SAADAVFhzAwAATIXkBgAAmArJDQAAMBWSGwAAYCokNwAAwFRIbgAAgKmQ3AAAAFMhuQEAAKZCcgMAAEyF5AYAAJgKyQ0AADAVkhsAAGAqJDcAAMBUSG4AAICpkNwAAABTIbkBAACmQnIDAABMheQGAACYCskNAAAwFZIbAABgKiQ3AADAVEhuAACAqZDcAAAAUyG5AQAApkJyAwAATIXkBgAAmArJDQAAMBWSGwAAYCo3uTqAq6HszYNcHQJgGqcOxro6BMAkal2Ts3hV7ePU8c6mvO/U8a4FUyY3AAD8U1ksTMrwDQAAAFOhcgMAgIlYqFuQ3AAAYCZMSzEtBQAATIbKDQAAJkLlhuQGAABTsVgsrg7B5UjvAACAqVC5AQDAVKhbkNwAAGAirLkhvQMAACZD5QYAABOhckNyAwCAqfCEYqalAACAyVC5AQDARJiWIrkBAMBUSG6YlgIAACZD5QYAABOhckNyAwCAqVjEu6VI7wAAgKlQuQEAwESYliK5AQDAVEhumJYCAAAmQ+UGAAAToXJD5QYAAJNxc/JWNDNnzlT9+vXl4+MjHx8fhYWF6YsvvrDvb926tSwWi8M2bNgwhzFSUlLUuXNnlS5dWgEBARozZoxyc3OL/Q1QuQEAAFescuXKev7553XLLbfIMAzNmzdP9957r7777jvVrVtXkjRkyBBNnjzZfkzp0qXtf+fl5alz584KCgrSxo0blZqaqgEDBsjDw0PPPfdcsWIhuQEAwERcNS3VtWtXh8/PPvusZs6cqU2bNtmTm9KlSysoKKjQ47/88kv98MMPWrNmjQIDA9WwYUM9/fTTGjdunCZOnChPT88ix8K0FAAAJmKxuDl1y8nJUVZWlsOWk5Nz2Rjy8vL0wQcf6PTp0woLC7O3L1iwQP7+/rr11lsVGxurM2fO2PclJSWpXr16CgwMtLeFh4crKytLe/bsKdZ3QHIDAAAuKT4+XjabzWGLj48vtO/u3bvl7e0tq9WqYcOGaenSpQoNDZUkPfDAA3rvvfe0bt06xcbGav78+erXr5/92LS0NIfERpL9c1paWrFiZloKAAATsTi5bhEbG6uYmBiHNqvVWmjf2rVra8eOHcrMzNTHH3+sqKgoJSYmKjQ0VEOHDrX3q1evnipWrKi2bdvqwIEDqlGjhlNjJrkBAMBEnL3mxmq1XjKZ+StPT0/VrFlTktSoUSNt3bpVr7zyit54440CfZs2bSpJ2r9/v2rUqKGgoCBt2bLFoU96erokXXKdzqUwLQUAAK6K/Pz8S67P2bFjhySpYsWKkqSwsDDt3r1bGRkZ9j6rV6+Wj4+PfWqrqKjcAABgIhaLa94KHhsbq06dOqlq1ao6deqUFi5cqPXr12vVqlU6cOCAFi5cqIiICPn5+WnXrl0aOXKkWrZsqfr160uSOnTooNDQUPXv319Tp05VWlqaJkyYoOjo6CJXji4iuQEAwERcdSt4RkaGBgwYoNTUVNlsNtWvX1+rVq1S+/bt9euvv2rNmjV6+eWXdfr0aVWpUkWRkZGaMGGC/Xh3d3etWLFCjzzyiMLCwlSmTBlFRUU5PBenqCyGYRjOvLjrQdmbB7k6BMA0Th2MdXUIgEnUuiZnqdrgGaeOl7Jzwt93us5QuQEAwEScfbfUjYjkBgAAE+HFmdwtBQAATIbKDQAAJkLlhuQGAABTYc0N01IAAMBkqNwAAGAmTEuR3AAAYCasuWFaCgAAmAyVGwAATMRV75a6npDcAABgItwtxbQUAAAwGSo3AACYCAuKSW4AADAX1twwLQUAAMyFyg0AAGZC2YLkBgAAU2FaivwOAACYC5UbAADMhMoNyQ0AAKbCnAxfAQAAMBcqNwAAmIjBtBTJDQAApkJuw7QUAAAwFyo3AACYiRulG5IbAADMhDU3TEsBAABzoXIDAICZULghuQEAwFRYc8O0FAAAMBcqNwAAmAkLikluAAAwFXIbpqUAAIC5ULkBAMBMWFBMcgMAgKmQ2zAtBQAAzIXKDQAAJmJwtxTJDQAApsKaG6alAACAuVC5AQDATCjcULkBAMBULBbnbkU0c+ZM1a9fXz4+PvLx8VFYWJi++OIL+/5z584pOjpafn5+8vb2VmRkpNLT0x3GSElJUefOnVW6dGkFBARozJgxys3NLfZXQHIDAACuWOXKlfX8889r+/bt2rZtm9q0aaN7771Xe/bskSSNHDlSy5cv16JFi5SYmKjDhw/r/vvvtx+fl5enzp076/z589q4caPmzZunuXPn6qmnnip2LBbDMAynXdl1ouzNg1wdAmAapw7GujoEwCRqXZOz1Oz2rlPH279sQImPLV++vF544QV1795dFSpU0MKFC9W9e3dJ0t69exUSEqKkpCQ1a9ZMX3zxhbp06aLDhw8rMDBQkjRr1iyNGzdOR44ckaenZ5HPS+UGAAAzsTh3y8nJUVZWlsOWk5Nz2RDy8vL0wQcf6PTp0woLC9P27dt14cIFtWvXzt6nTp06qlq1qpKSkiRJSUlJqlevnj2xkaTw8HBlZWXZqz9FRXIDAAAuKT4+XjabzWGLj48vtO/u3bvl7e0tq9WqYcOGaenSpQoNDVVaWpo8PT3l6+vr0D8wMFBpaWmSpLS0NIfE5uL+i/uKg7ulAAAwEyc/xC82NlYxMTEObVartdC+tWvX1o4dO5SZmamPP/5YUVFRSkxMdGo8RUFyAwCAmTg5ubFarZdMZv7K09NTNWvWlCQ1atRIW7du1SuvvKJevXrp/PnzOnnypEP1Jj09XUFBQZKkoKAgbdmyxWG8i3dTXexTVExLAQCAqyI/P185OTlq1KiRPDw8lJCQYN+XnJyslJQUhYWFSZLCwsK0e/duZWRk2PusXr1aPj4+Cg0NLdZ5qdwAAGAmLipbxMbGqlOnTqpatapOnTqlhQsXav369Vq1apVsNpsGDx6smJgYlS9fXj4+PhoxYoTCwsLUrFkzSVKHDh0UGhqq/v37a+rUqUpLS9OECRMUHR1d5MrRRSQ3AACYiYtenJmRkaEBAwYoNTVVNptN9evX16pVq9S+fXtJ0vTp0+Xm5qbIyEjl5OQoPDxcr7/+uv14d3d3rVixQo888ojCwsJUpkwZRUVFafLkycWOhefcALgsnnMDOMs1es5NzwVOHW//R32dOt61QOUGAAAz4d1SJDcAAJiJ4UZ2w91SAADAVKjcwGkG971bD/W7W1X/5S9J2rvvdz0/41OtTtytqv/y056vXyz0uP7Rr2nZ59t0a0gVxQyLUFjjWvIr762U345q9oL1mjl39bW8DOCGsmDBZ5o9e4mOHDmhOnVu1n/+87Dq1782aztwnXLRguLrCckNnOZw2nHFTflYB35Jl8UiPRDZQh+8+ZhadInTTwdSVeOOxx36D+rTWo8P7ajV63dLkm67tZqOHDulh2Le1O+Hj6tpo5qa8VyU8vLz9ea7CYWdEvhH+/zzrxQf/7YmTYpWgwa1NG/epxo8+CmtXDlLfn6+rg4PrkJuQ3ID5/kiYafD58kvLtHgvneryW01tHffYWUczXLY3zX8di39bKtOn/njBWzzF33lsP+XX4+oye01dE94I5IboBBz5ixTz57hioz842WEkyY9qvXrt2rx4tUaOrSHi6MDXIc1N7gq3NwsiuzSRGW8rNr87YEC+xveGqwGdYP17kdfFXL0//iULa0TmdlXK0zghnX+/AXt2bNfzZs3sLe5ubmpefOG+u67ZBdGBpdzszh3uwG5tHJz9OhRvfPOO0pKSrK/8TMoKEjNmzfXwIEDVaFCBVeGhxIIrV1ZCYv/rVJWD2WfydEDw/6r5P2HC/Qb0LOl9u77XZu/3X/JsZreXlORne9Q98EvX8WIgRvTiRNZysvLl59fOYd2Pz9f/fzzby6KCtcF1ty4rnKzdetW1apVSzNmzJDNZlPLli3VsmVL2Ww2zZgxQ3Xq1NG2bdv+dpycnBxlZWU5bIaRdw2uAIXZ93OqWnSO0933Pa3Z763TGy8+pNo1Kzn0KWX1UI97m122ahNS61/64M3HFD/jU639as/VDhsAYCIuq9yMGDFCPXr00KxZs2T5S5ZpGIaGDRumESNGKCkp6bLjxMfHa9KkSQ5tHrYGspa7zekx4+9duJCnnw/98dKzHd8f0u31q+nRQe31+L/n2ft0i2is0qU89f6SjYWOUbtmJa1YMEZzPlivF/67/JrEDdxoypXzkbu7m44dO+HQfuzYSfn7l7vEUfhHoHDjusrNzp07NXLkyAKJjSRZLBaNHDlSO3bs+NtxYmNjlZmZ6bB5+ta/ChGjJNzc3GT1dMyhB/Rsqc8TvtPR46cK9K9zSyV9/v5YLVz8jSa/uORahQnccDw9PVS3bk0lJe2yt+Xn5yspaaduu622CyODy7HmxnWVm6CgIG3ZskV16tQpdP+WLVsUGBj4t+NYrdYCbwu1WNydEiOKZ+KY7lqduEu//n5M3t5e6nlPM93VrLa6RU2z96keHKAWTWopctD0AseH1PqXPlswVmu++l6vvr1KAf4+kqT8fKPQRAj4pxs0qJvGjZuuW2+tqfr1a2nevE909uw53X9/O1eHBriUy5Kb0aNHa+jQodq+fbvatm1rT2TS09OVkJCgt956Sy++WPhD33B9quBXVm9MG6KgCjZlnTqr7/f+qm5R07Tu6x/sffr3uEu/p55QQiHraLp1aqwK/j7qc19z9bmvub390G9HdetdY67JNQA3koiIu3T8eKZmzFigI0dOKCSkut5+exLTUv90N2i1xZlc+lbwDz/8UNOnT9f27duVl/fHImB3d3c1atRIMTEx6tmzZ4nG5a3ggPPwVnDAWa7Nk6OrP7TIqeP9/PaN98wkl94K3qtXL/Xq1UsXLlzQ0aNHJUn+/v7y8PBwZVgAAOAGdl08odjDw0MVK1Z0dRgAANz4mJa6PpIbAADgJDzEj9cvAAAAc6FyAwCAmTAtRXIDAICpMCfDVwAAAMyFyg0AAGbCgmIqNwAAwFyo3AAAYCYsKCa5AQDATAympZiWAgAA5kLlBgAAM6FsQXIDAICpsOaG/A4AAJgLlRsAAMyEBcUkNwAAmArTUkxLAQAAc6FyAwCAmVC4IbkBAMBMDKalmJYCAADmQuUGAAAzoXJDcgMAgKlwKzjTUgAAwFyo3AAAYCaULUhuAAAwFaalyO8AAMCVi4+P1x133KGyZcsqICBA3bp1U3JyskOf1q1by2KxOGzDhg1z6JOSkqLOnTurdOnSCggI0JgxY5Sbm1usWKjcAABgJi66WyoxMVHR0dG64447lJubq/Hjx6tDhw764YcfVKZMGXu/IUOGaPLkyfbPpUuXtv+dl5enzp07KygoSBs3blRqaqoGDBggDw8PPffcc0WOheQGAAAzcVFys3LlSofPc+fOVUBAgLZv366WLVva20uXLq2goKBCx/jyyy/1ww8/aM2aNQoMDFTDhg319NNPa9y4cZo4caI8PT2LFAvTUgAA4JJycnKUlZXlsOXk5PztcZmZmZKk8uXLO7QvWLBA/v7+uvXWWxUbG6szZ87Y9yUlJalevXoKDAy0t4WHhysrK0t79uwpcswkNwAAmIhhsTh1i4+Pl81mc9ji4+MvG0N+fr6eeOIJtWjRQrfeequ9/YEHHtB7772ndevWKTY2VvPnz1e/fv3s+9PS0hwSG0n2z2lpaUX+DpiWAgDATJxctoiNjVVMTIxDm9Vqvewx0dHR+v777/X11187tA8dOtT+d7169VSxYkW1bdtWBw4cUI0aNZwWM5UbAABwSVarVT4+Pg7b5ZKb4cOHa8WKFVq3bp0qV6582bGbNm0qSdq/f78kKSgoSOnp6Q59Ln6+1DqdwpDcAABgJhaLc7ciMgxDw4cP19KlS7V27VrdfPPNf3vMjh07JEkVK1aUJIWFhWn37t3KyMiw91m9erV8fHwUGhpa5FiYlgIAwExcdLdUdHS0Fi5cqE8++URly5a1r5Gx2Wzy8vLSgQMHtHDhQkVERMjPz0+7du3SyJEj1bJlS9WvX1+S1KFDB4WGhqp///6aOnWq0tLSNGHCBEVHR//tVNifUbkBAABXbObMmcrMzFTr1q1VsWJF+/bhhx9Kkjw9PbVmzRp16NBBderU0ahRoxQZGanly5fbx3B3d9eKFSvk7u6usLAw9evXTwMGDHB4Lk5RULkBAMBMXFS5MQzjsvurVKmixMTEvx0nODhYn3/++RXFQnIDAICZ8GoppqUAAIC5ULkBAMBEDBdNS11PSG4AADCTYty+bVZMSwEAAFOhcgMAgJkwLUVyAwCAqZDbMC0FAADMhcoNAAAm4kbZguQGAAAz4WYppqUAAIDJULkBAMBEqNyQ3AAAYCoWshumpQAAgLlQuQEAwEQo3JDcAABgKiQ3TEsBAACToXIDAICJWChbkNwAAGAmTEsxLQUAAEyGyg0AACbiRuWG5AYAADNhWoppKQAAYDJUbgAAMBEqNyQ3AACYCu+WKkZyk5WVVeRBfXx8ShQMAADAlSpycuPr61vkbDAvL6/EAQEAgJLjIX7FSG7WrVtn//uXX37Rk08+qYEDByosLEySlJSUpHnz5ik+Pt75UQIAgCJhVqoYyU2rVq3sf0+ePFkvvfSS+vTpY2+75557VK9ePb355puKiopybpQAAABFVKLiVVJSkho3blygvXHjxtqyZcsVBwUAAErGYnHudiMqUXJTpUoVvfXWWwXa3377bVWpUuWKgwIAACVDclPCW8GnT5+uyMhIffHFF2ratKkkacuWLdq3b58WL17s1AABAACKo0SVm4iICP3000/q2rWrjh8/ruPHj6tr16766aefFBER4ewYAQBAEblZnLvdiEr8EL8qVaroueeec2YsAADgCt2oU0nOVOK74b/66iv169dPzZs31++//y5Jmj9/vr7++munBQcAAFBcJUpuFi9erPDwcHl5eenbb79VTk6OJCkzM5NqDgAALsSC4hImN88884xmzZqlt956Sx4eHvb2Fi1a6Ntvv3VacAAAoHgsbhanbjeiEiU3ycnJatmyZYF2m82mkydPXmlMAAAAJVai5CYoKEj79+8v0P7111+revXqVxwUAAAoGaalSpjcDBkyRI8//rg2b94si8Wiw4cPa8GCBRo9erQeeeQRZ8cIAACKyFXJTXx8vO644w6VLVtWAQEB6tatm5KTkx36nDt3TtHR0fLz85O3t7ciIyOVnp7u0CclJUWdO3dW6dKlFRAQoDFjxig3N7dY30GJbgV/8sknlZ+fr7Zt2+rMmTNq2bKlrFarRo8erREjRpRkSAAAcANLTExUdHS07rjjDuXm5mr8+PHq0KGDfvjhB5UpU0aSNHLkSH322WdatGiRbDabhg8frvvvv1/ffPONJCkvL0+dO3dWUFCQNm7cqNTUVA0YMEAeHh7FumHJYhiGUdILOX/+vPbv36/s7GyFhobK29u7pEM5VdmbB7k6BMA0Th2MdXUIgEnUuiZnabbYuY9k2RR5Z4mOO3LkiAICApSYmKiWLVsqMzNTFSpU0MKFC9W9e3dJ0t69exUSEqKkpCQ1a9ZMX3zxhbp06aLDhw8rMDBQkjRr1iyNGzdOR44ckaenZ5HOXaJpqQcffFCnTp2Sp6enQkND1aRJE3l7e+v06dN68MEHSzIkAABwguvlCcWZmZmSpPLly0uStm/frgsXLqhdu3b2PnXq1FHVqlWVlJQk6Y8Xc9erV8+e2EhSeHi4srKytGfPnqJ/ByUJeN68eTp79myB9rNnz+rdd98tyZAAAOA6lJOTo6ysLIft4vPtLiU/P19PPPGEWrRooVtvvVWSlJaWJk9PT/n6+jr0DQwMVFpamr3PnxObi/sv7iuqYiU3WVlZyszMlGEYOnXqlMOFnjhxQp9//rkCAgKKMyQAAHAiZy8ojo+Pl81mc9ji4+MvG0N0dLS+//57ffDBB9foqh0Va0Gxr6+vLBaLLBaLatUqOHdosVg0adIkpwUHAACKx1LiFysVLjY2VjExMQ5tVqv1kv2HDx+uFStWaMOGDapcubK9PSgoSOfPn9fJkycdqjfp6ekKCgqy99myZYvDeBfvprrYpyiKldysW7dOhmGoTZs2Wrx4sX0eTZI8PT0VHBysSpUqFWdIAABwHbNarZdNZi4yDEMjRozQ0qVLtX79et18880O+xs1aiQPDw8lJCQoMjJS0h8PBU5JSVFYWJgkKSwsTM8++6wyMjLsM0GrV6+Wj4+PQkNDixxzsZKbVq1aSZIOHjyoqlWrynKjPt0HAACTctV/mqOjo7Vw4UJ98sknKlu2rH2NjM1mk5eXl2w2mwYPHqyYmBiVL19ePj4+GjFihMLCwtSsWTNJUocOHRQaGqr+/ftr6tSpSktL04QJExQdHV2kBOuiEj3nZu3atfL29laPHj0c2hctWqQzZ84oKiqqJMMCAIAr5KrCw8yZMyVJrVu3dmifM2eOBg4cKEmaPn263NzcFBkZqZycHIWHh+v111+393V3d9eKFSv0yCOPKCwsTGXKlFFUVJQmT55crFhK9JybWrVq6Y033tDdd9/t0J6YmKihQ4cWeCLhtcZzbgDn4Tk3gLNcm+fctFz+jVPH29C1hVPHuxZKVLlJSUkpMJcmScHBwUpJSbnioAAAQMmwYqSEz7kJCAjQrl27CrTv3LlTfn5+VxwUAAAoGV6cWcLkpk+fPnrssce0bt065eXlKS8vT2vXrtXjjz+u3r17OztGAACAIivRtNTTTz+tX375RW3bttVNN/0xRH5+vgYMGFCsF1sBAADnulGrLc50RS/O/Omnn7Rz5055eXmpXr16Cg4OdmZsV+AnVwcAmIZX1ThXhwCYwtmU96/Jedp+4dwFxQmd/iELii+qVatWoU8qBgAAcJUiJzcxMTF6+umnVaZMmQKPYf6rl1566YoDAwAAxXclb/I2iyInN999950uXLhg//tSeGoxAACu42Yp8WoT0yhycrNu3bpC/wYAALieXNGaGwAAcH1hWqoYyc39999f5EGXLFlSomAAAMCVKdED7EymyN+BzWazbz4+PkpISNC2bdvs+7dv366EhATZbLarEigAAEBRFLlyM2fOHPvf48aNU8+ePTVr1iy5u7tLkvLy8vToo4/Kx8fH+VECAIAiYUFxCatX77zzjkaPHm1PbKQ/XlMeExOjd955x2nBAQCA4nGzOHe7EZUoucnNzdXevXsLtO/du1f5+flXHBQAAEBJlehuqUGDBmnw4ME6cOCAmjRpIknavHmznn/+eQ0aNMipAQIAgKJjQXEJk5sXX3xRQUFBmjZtmlJTUyVJFStW1JgxYzRq1CinBggAAIruRp1KcqYSJTdubm4aO3asxo4dq6ysLEliITEAALgulLh6lZubqzVr1uj999+3v3Lh8OHDys7OdlpwAACgeCwWw6nbjahElZtDhw6pY8eOSklJUU5Ojtq3b6+yZctqypQpysnJ0axZs5wdJwAAKAKmpUpYuXn88cfVuHFjnThxQl5eXvb2++67TwkJCU4LDgAAoLhKVLn56quvtHHjRnl6ejq0V6tWTb///rtTAgMAAMXH3VIlTG7y8/OVl5dXoP23335T2bJlrzgoAABQMjyhuIQJXocOHfTyyy/bP1ssFmVnZysuLk4RERHOig0AAKDYSvycm44dOyo0NFTnzp3TAw88oH379snf31/vv/++s2MEAABFxILiEiY3VapU0c6dO/Xhhx9q586dys7O1uDBg9W3b1+HBcYAAODaYs1NCZKbCxcuqE6dOlqxYoX69u2rvn37Xo24AAAASqTYyY2Hh4fOnTt3NWIBAABXiGmpElavoqOjNWXKFOXm5jo7HgAAcAXcLIZTtxtRidbcbN26VQkJCfryyy9Vr149lSlTxmH/kiVLnBIcAABAcZUoufH19VVkZKSzYwEAAFeIaaliJjf5+fl64YUX9NNPP+n8+fNq06aNJk6cyB1SAABcJ7hbqpjfwbPPPqvx48fL29tb//rXvzRjxgxFR0dfrdgAAACKrVjJzbvvvqvXX39dq1at0rJly7R8+XItWLBA+fn5Vys+AABQDCwoLmZyk5KS4vB6hXbt2slisejw4cNODwwAABSfm8W5242oWMlNbm6uSpUq5dDm4eGhCxcuODUoAACAkirWgmLDMDRw4EBZrVZ727lz5zRs2DCH28G5FRwAANe4UastzlSs5CYqKqpAW79+/ZwWDAAAuDLcLVXM5GbOnDlXKw4AAACnKNFD/AAAwPXpRr3DyZmoXgEAYCKuvFtqw4YN6tq1qypVqiSLxaJly5Y57B84cKAsFovD1rFjR4c+x48fV9++feXj4yNfX18NHjxY2dnZxfsOihc2AABA4U6fPq0GDRrotddeu2Sfjh07KjU11b69//77Dvv79u2rPXv2aPXq1VqxYoU2bNigoUOHFisOpqUAADARV1YtOnXqpE6dOl22j9VqVVBQUKH7fvzxR61cuVJbt25V48aNJUmvvvqqIiIi9OKLL6pSpUpFioPKDQAAJuLsaamcnBxlZWU5bDk5OSWOb/369QoICFDt2rX1yCOP6NixY/Z9SUlJ8vX1tSc20h8PDHZzc9PmzZuL/h2UODoAAGB68fHxstlsDlt8fHyJxurYsaPeffddJSQkaMqUKUpMTFSnTp2Ul5cnSUpLS1NAQIDDMTfddJPKly+vtLS0Ip+HaSkAAEzE4uS7pWJjYxUTE+PQ9ueH+RZH79697X/Xq1dP9evXV40aNbR+/Xq1bdv2iuL8M5IbAABMxNlPKLZarSVOZv5O9erV5e/vr/3796tt27YKCgpSRkaGQ5/c3FwdP378kut0CsO0FAAAcInffvtNx44dU8WKFSVJYWFhOnnypLZv327vs3btWuXn56tp06ZFHpfKDQAAJuLKqkV2drb2799v/3zw4EHt2LFD5cuXV/ny5TVp0iRFRkYqKChIBw4c0NixY1WzZk2Fh4dLkkJCQtSxY0cNGTJEs2bN0oULFzR8+HD17t27yHdKSSQ3AACYiiufULxt2zbdfffd9s8X1+pERUVp5syZ2rVrl+bNm6eTJ0+qUqVK6tChg55++mmHaa8FCxZo+PDhatu2rdzc3BQZGakZM2YUKw6SGwAA4BStW7eWYVw6uVq1atXfjlG+fHktXLjwiuIguQEAwEScvaD4RkRyAwCAiZDccLcUAAAwGSo3AACYiLurA7gOkNwAAGAirrxb6nrBtBQAADAVKjcAAJgIC4pJbgAAMBWSG6alAACAyVC5AQDARNyp3JDcAABgJkxLMS0FAABMhsoNAAAmwnNuSG4AADAVpqWYlgIAACZD5QYAABPh3VIkNwAAmArTUkxLAQAAk6FyAwCAiXC3FMkNAACmwhOKmZYCAAAmQ+UGAAATYUExyQ0AAKZCcsO0FAAAMBkqNwAAmAiVG5IbAABMxZ1bwZmWAgAA5kLlBgAAE6FqQXIDAICpsOaGBA8AAJgMlRsAAEyEyg3JDQAApsLdUkxLAQAAk6FyAwCAiTAtRXIDAICpkNwwLQUAAEyGyg0AACZC5YbkBgAAU3EnuWFaCgAAmAuVGwAATMSN59xQuQEAwEzcnLwVx4YNG9S1a1dVqlRJFotFy5Ytc9hvGIaeeuopVaxYUV5eXmrXrp327dvn0Of48ePq27evfHx85Ovrq8GDBys7O7tYcZDcAAAApzh9+rQaNGig1157rdD9U6dO1YwZMzRr1ixt3rxZZcqUUXh4uM6dO2fv07dvX+3Zs0erV6/WihUrtGHDBg0dOrRYcVgMwzBh/eonVwcAmIZX1ThXhwCYwtmU96/JedYe/typ47WpFFGi4ywWi5YuXapu3bpJ+qNqU6lSJY0aNUqjR4+WJGVmZiowMFBz585V79699eOPPyo0NFRbt25V48aNJUkrV65URESEfvvtN1WqVKlI56ZyAwCAibhbnLvl5OQoKyvLYcvJySl2XAcPHlRaWpratWtnb7PZbGratKmSkpIkSUlJSfL19bUnNpLUrl07ubm5afPmzUU+F8kNrrkFCz5TmzaDVa/e/erRY5R27aLSBvzZkH7ttGXVFKXvma30PbO1fukkdWjdQJJUtbK/zqa8X+h2f+em9jFat6irdUsmKeOHd3Rw20w9E9tH7u78Kx/FFx8fL5vN5rDFx8cXe5y0tDRJUmBgoEN7YGCgfV9aWpoCAgIc9t90000qX768vU9RcLcUrqnPP/9K8fFva9KkaDVoUEvz5n2qwYOf0sqVs+Tn5+vq8IDrwu9px/Wf59/X/oNpslikft1batHbo9UsIlbJ+39XtUbDHPo/+EBbjXy4i1at2yFJqhdSVcvmjtOU/y7T4JGvq1JQeb363GC5u7kp9tkFLrgiXEvOvlsqNjZWMTExDm1Wq9Wp53A20nhcU3PmLFPPnuGKjGynmjWratKkR1WqlFWLF692dWjAdePzNd9q1bodOvBLmvYfTNPEFz5S9plzanJbTeXnG0o/kumw3RN+hxav2KTTZ/6YKujeNUzf701R/CtL9POhdH29+Uf9O36hHo7qIO8ypVx8dbja3CzO3axWq3x8fBy2kiQ3QUFBkqT09HSH9vT0dPu+oKAgZWRkOOzPzc3V8ePH7X2K9B0UOzqghM6fv6A9e/arefMG9jY3Nzc1b95Q332X7MLIgOuXm5tFPbqGqYyXVZu/3Vdg/231blbDW6tp3ofr7G1WTw+dy7ng0O/sufPyKuWp2+rdfNVjBgpz8803KygoSAkJCfa2rKwsbd68WWFhYZKksLAwnTx5Utu3b7f3Wbt2rfLz89W0adMCY17KdZ3c/Prrr3rwwQcv26fwhU7nr1GEKI4TJ7KUl5cvP79yDu1+fr46evSEi6ICrk91a1fRkR/nKHP/fM14brB6DX1Je/f9XqBfVK+79eO+37Rp+/8Sn9WJO9WsUS31vKe53NwsqhRYTuMfv1+SVDGgXIExYC7OrtwUR3Z2tnbs2KEdO3ZI+mMR8Y4dO5SSkiKLxaInnnhCzzzzjD799FPt3r1bAwYMUKVKlex3VIWEhKhjx44aMmSItmzZom+++UbDhw9X7969i3ynlHSdJzfHjx/XvHnzLtun8IVOb1yjCAHg6vjp58Nq2vFJtbz3P3rrvTV666VHVOeWfzn0KWX1UK97m2veB+sd2hO+2q3xzy7QjOcGK3P/fO1KfMm+HiffyL9GVwBXceVD/LZt26bbbrtNt912myQpJiZGt912m5566ilJ0tixYzVixAgNHTpUd9xxh7Kzs7Vy5UqVKvW/6dIFCxaoTp06atu2rSIiInTnnXfqzTffLFYcLn3OzaeffnrZ/T///LNGjRqlvLy8S/bJyckpcEua1Zoiq9XTKTHCec6fv6CGDbtrxown1a5dmL193Ljpyso6rZkzJ7gwOlwKz7m5Pny2cLx+PpSuEbGz7W197r9Ts6Y+rBpNHtXR46cKPa5iYDmdOJmt4CoVtGPtNN3Z5d/avuvnaxU2/uRaPedmc8ZnTh2vaUBnp453Lbj0bqlu3brJYrHocvmVxXL5mpjVai1kYROJzfXI09NDdevWVFLSLntyk5+fr6SknerX78b78QDXkpvFTVZPD4e2gb3u1mdrtl8ysZGk1PQ/pnx73tNcv/5+VN99f/CqxgnX+5v/bP4juHRaqmLFilqyZIny8/ML3b799ltXhoerYNCgbvroo1VaujRBBw78qokTX9fZs+d0//3t/v5g4B9i8rjeatGkjqpW9lfd2lU0eVxvtQwL0QfLvrH3qR4cqDub1tGc99cVOsbIh7uobu0qCqlVWU8+dp9GP3qvRsXNU36+CR9KDwcWJ283IpdWbho1aqTt27fr3nvvLXT/31V1cOOJiLhLx49nasaMBTpy5IRCQqrr7bcnyd+fRY7ARRX8fDR7+qMKCvBV5qkz+n5virr2f15rv9pt7xPVq7V+Tz2uNRt2FTpGh9YNNXZ4N1mtHtr9wyH1eOhFfbl+57W6BMClXLrm5quvvtLp06fVsWPHQvefPn1a27ZtU6tWrYo5Mk+8BZyFNTeAc1yrNTfbjjp3zU1j/xtv2YBLKzd33XXXZfeXKVOmBIkNAAD/XNf1bdDXCN8BAAAwFd4tBQCAiVic/G6pGxHJDQAAJnKj3uHkTExLAQAAU6FyAwCAifAQPyo3AADAZKjcAABgIhRuSG4AADAVN7IbpqUAAIC5ULkBAMBEKNyQ3AAAYCrcLcW0FAAAMBkqNwAAmAiFG5IbAABMheSGaSkAAGAyVG4AADARnnNDcgMAgKmQ2zAtBQAATIbKDQAAJmKxGK4OweVIbgAAMBGmpZiWAgAAJkPlBgAAE+H1CyQ3AACYClMyfAcAAMBkqNwAAGAiTEuR3AAAYCrkNkxLAQAAk6FyAwCAiTAtRXIDAICpkNswLQUAAEyGyg0AACbiRumG5AYAADMht2FaCgAAmAyVGwAATMRiMVwdgsuR3AAAYCJMSzEtBQAAnGDixImyWCwOW506dez7z507p+joaPn5+cnb21uRkZFKT0+/KrGQ3AAAYCIWi3O34qhbt65SU1Pt29dff23fN3LkSC1fvlyLFi1SYmKiDh8+rPvvv9/JV/8HpqUAADARV05L3XTTTQoKCirQnpmZqdmzZ2vhwoVq06aNJGnOnDkKCQnRpk2b1KxZM6fGQeUGAABcUk5OjrKyshy2nJycQvvu27dPlSpVUvXq1dW3b1+lpKRIkrZv364LFy6oXbt29r516tRR1apVlZSU5PSYSW4AADARNydv8fHxstlsDlt8fHyB8zZt2lRz587VypUrNXPmTB08eFB33XWXTp06pbS0NHl6esrX19fhmMDAQKWlpTn9O2BaCgAAE3H2izNjY2MVExPj0Ga1Wgv069Spk/3v+vXrq2nTpgoODtZHH30kLy8v5wb1N6jcAACAS7JarfLx8XHYCktu/srX11e1atXS/v37FRQUpPPnz+vkyZMOfdLT0wtdo3OlSG4AADAVi5O3ksnOztaBAwdUsWJFNWrUSB4eHkpISLDvT05OVkpKisLCwkp8jkthWgoAABOxuOh+qdGjR6tr164KDg7W4cOHFRcXJ3d3d/Xp00c2m02DBw9WTEyMypcvLx8fH40YMUJhYWFOv1NKIrkBAABO8Ntvv6lPnz46duyYKlSooDvvvFObNm1ShQoVJEnTp0+Xm5ubIiMjlZOTo/DwcL3++utXJRaLYRgmfAnFT64OADANr6pxrg4BMIWzKe9fk/OcPP+5U8fz9Yxw6njXApUbAABMhbdLsaAYAACYCpUbAABMxFULiq8nJDcAAJgKyQ3TUgAAwFSo3AAAYCIWC3ULkhsAAEyFaSnSOwAAYCpUbgAAMBHuliK5AQDAVEhumJYCAAAmQ+UGAABToW5BcgMAgIlYLExLkd4BAABToXIDAICpULkhuQEAwES4W4ppKQAAYDJUbgAAMBXqFiQ3AACYCNNSpHcAAMBkqNwAAGAiPOeG5AYAAJMhuWFaCgAAmAqVGwAATMRC3YLkBgAAc2FaivQOAACYCpUbAABMhLulSG4AADAZkhumpQAAgKlQuQEAwES4W4rkBgAAk2FaivQOAACYCpUbAABMhLeCk9wAAGAq3ArOtBQAADAZKjcAAJgKdQuSGwAATIQ1N6R3AADAZKjcAABgKlRuSG4AADAR7pZiWgoAADjRa6+9pmrVqqlUqVJq2rSptmzZcs1jILkBAMBU3Jy8Fd2HH36omJgYxcXF6dtvv1WDBg0UHh6ujIwMZ1xYkZHcAABgIhYn/19xvPTSSxoyZIgGDRqk0NBQzZo1S6VLl9Y777xzla62cCQ3AADgknJycpSVleWw5eTkFOh3/vx5bd++Xe3atbO3ubm5qV27dkpKSrqWIZt1QXEtVweAv5GTk6P4+HjFxsbKarW6OhxcxtmU910dAi6D3xIKcu5/A+PjJ2rSpEkObXFxcZo4caJD29GjR5WXl6fAwECH9sDAQO3du9epMf0di2EYxjU9IyApKytLNptNmZmZ8vHxcXU4wA2L3xKutpycnAKVGqvVWiCZPnz4sP71r39p48aNCgsLs7ePHTtWiYmJ2rx58zWJVzJt5QYAADhDYYlMYfz9/eXu7q709HSH9vT0dAUFBV2t8ArFmhsAAHDFPD091ahRIyUkJNjb8vPzlZCQ4FDJuRao3AAAAKeIiYlRVFSUGjdurCZNmujll1/W6dOnNWjQoGsaB8kNXMJqtSouLo4FkMAV4reE60mvXr105MgRPfXUU0pLS1PDhg21cuXKAouMrzYWFAMAAFNhzQ0AADAVkhsAAGAqJDcAAMBUSG5w1a1fv14Wi0UnT568quf55ZdfZLFYtGPHjkued9myZapZs6bc3d31xBNPXNV4gKKyWCxatmzZVT9PtWrV9PLLL1/yvHv37lWzZs1UqlQpNWzY8KrHA1wtJDf/IAMHDpTFYtHzzz/v0L5s2TJZLEV/Odpf/wV5vWrevLlSU1Nls9nsbQ8//LC6d++uX3/9VU8//bQGDhyobt26uS5I/CMcOXJEjzzyiKpWrSqr1aqgoCCFh4frm2++cWlcqamp6tSpk/1zXFycypQpo+TkZCUkJGju3Lny9fV1XYBACXEr+D9MqVKlNGXKFD388MMqV66cq8O5qjw9PR2eipmdna2MjAyFh4erUqVKLowM/zSRkZE6f/685s2bp+rVqys9PV0JCQk6duyYS+P661NjDxw4oM6dOys4ONhFEQHOQeXmH6Zdu3YKCgpSfHz8JfssXrxYdevWldVqVbVq1TRt2jT7vtatW+vQoUMaOXKkLBaLveJz6NAhde3aVeXKlVOZMmVUt25dff755w7jbt++XY0bN1bp0qXVvHlzJScnO+yfOXOmatSoIU9PT9WuXVvz58932G+xWDRz5kx16tRJXl5eql69uj7++ONLXsefp6XWr1+vsmXLSpLatGkji8Wi1q1ba968efrkk0/s17J+/foifY9AUZ08eVJfffWVpkyZorvvvlvBwcFq0qSJYmNjdc8999j7HT16VPfdd59Kly6tW265RZ9++qnDOImJiWrSpImsVqsqVqyoJ598Urm5ufb9rVu31vDhwzV8+HDZbDb5+/vrP//5jy73tI8/T0tZLBZt375dkydPtv8+Bg0apMzMTPvv468vSgSuWwb+MaKioox7773XWLJkiVGqVCnj119/NQzDMJYuXWpc/J/Ctm3bDDc3N2Py5MlGcnKyMWfOHMPLy8uYM2eOYRiGcezYMaNy5crG5MmTjdTUVCM1NdUwDMPo3Lmz0b59e2PXrl3GgQMHjOXLlxuJiYmGYRjGunXrDElG06ZNjfXr1xt79uwx7rrrLqN58+b22JYsWWJ4eHgYr732mpGcnGxMmzbNcHd3N9auXWvvI8nw8/Mz3nrrLSM5OdmYMGGC4e7ubvzwww+GYRjGwYMHDUnGd99953DeEydOGDk5OUZycrIhyVi8eLGRmppqZGZmGj179jQ6duxov5acnJyr+s8A/zwXLlwwvL29jSeeeMI4d+5coX0kGZUrVzYWLlxo7Nu3z3jssccMb29v49ixY4ZhGMZvv/1mlC5d2nj00UeNH3/80Vi6dKnh7+9vxMXF2cdo1aqV4e3tbTz++OPG3r17jffee88oXbq08eabb9r7BAcHG9OnT3c479KlSw3DMIzU1FSjbt26xqhRo+y/j5dfftnw8fGx/z5OnTrl9O8HuBpIbv5BLiY3hmEYzZo1Mx588EHDMByTmwceeMBo3769w3FjxowxQkND7Z//+i9IwzCMevXqGRMnTiz0vBeTjDVr1tjbPvvsM0OScfbsWcMwDKN58+bGkCFDHI7r0aOHERERYf8syRg2bJhDn6ZNmxqPPPKIYRiXT24MwzBOnDhhSDLWrVtX6HcCXC0ff/yxUa5cOaNUqVJG8+bNjdjYWGPnzp32/ZKMCRMm2D9nZ2cbkowvvvjCMAzDGD9+vFG7dm0jPz/f3ue1114zvL29jby8PMMw/khuQkJCHPqMGzfOCAkJsX++XHJjGIbRoEEDh4Rpzpw5hs1mu9LLB645pqX+oaZMmaJ58+bpxx9/dGj/8ccf1aJFC4e2Fi1aaN++fcrLy7vkeI899pieeeYZtWjRQnFxcdq1a1eBPvXr17f/XbFiRUlSRkbGZc/71/j++vK1sLCwAn2A601kZKQOHz6sTz/9VB07dtT69et1++23a+7cufY+f/59lClTRj4+Pg6/j7CwMIeF/y1atFB2drZ+++03e1uzZs0c+oSFhf3tbxcwI5Kbf6iWLVsqPDxcsbGxThnvoYce0s8//6z+/ftr9+7daty4sV599VWHPh4eHva/L/4LOD8/3ynnB653pUqVUvv27fWf//xHGzdu1MCBAxUXF2ff/+ffh/THb4TfB1AyJDf/YM8//7yWL1+upKQke1tISEiB21O/+eYb1apVS+7u7pL+uAupsP9PsEqVKho2bJiWLFmiUaNG6a233ipyLJc6b2hoqEPbpk2bCnwOCQkp8nn+6lLXAlxtoaGhOn36dJH6hoSEKCkpyWFx8DfffKOyZcuqcuXK9rbNmzc7HLdp0ybdcsst9t9ucfH7wI2K5OYfrF69eurbt69mzJhhbxs1apQSEhL09NNP66efftK8efP03//+V6NHj7b3qVatmjZs2KDff/9dR48elSQ98cQTWrVqlQ4ePKhvv/1W69atK1bSMWbMGM2dO1czZ87Uvn379NJLL2nJkiUO55WkRYsW6Z133tFPP/2kuLg4bdmyRcOHDy/xd1CtWjXt2rVLycnJOnr0qC5cuFDisYDCHDt2TG3atNF7772nXbt26eDBg1q0aJGmTp2qe++9t0hjPProo/r11181YsQI7d27V5988oni4uIUExMjN7f//Ws8JSVFMTExSk5O1vvvv69XX31Vjz/+eIljr1atmrKzs5WQkKCjR4/qzJkzJR4LuKZcvegH105hi2cPHjxoeHp6Gn/+n8LHH39shIaGGh4eHkbVqlWNF154weGYpKQko379+obVarUfN3z4cKNGjRqG1Wo1KlSoYPTv3984evSoYRgFF/YahmF89913hiTj4MGD9rbXX3/dqF69uuHh4WHUqlXLePfddx3OK8l47bXXjPbt2xtWq9WoVq2a8eGHHzpci4q5oDgjI8No37694e3tXWAf4Aznzp0znnzySeP22283bDabUbp0aaN27drGhAkTjDNnzhiGUXBhr2EYhs1ms9+laBiGsX79euOOO+4wPD09jaCgIGPcuHHGhQsX7PtbtWplPProo8awYcMMHx8fo1y5csb48eMdFhgXd0GxYRjGsGHDDD8/P0NSgX3A9cpiGJd5CAJwHbFYLFq6dClPFAYK0bp1azVs2PCGeHo4cLUxLQUAAEyF5AYAAJgK01IAAMBUqNwAAABTIbkBAACmQnIDAABMheQGAACYCskNgGvCYrFo2bJlrg4DwD8AyQ1gQklJSXJ3d1fnzp2LdVy1atV4CByAGx7JDWBCs2fP1ogRI7RhwwYdPnzY1eEAwDVFcgOYTHZ2tj788EM98sgj6ty5s+bOneuwf/ny5brjjjtUqlQp+fv767777pP0x+P7Dx06pJEjR8pischisUiSJk6cqIYNGzqM8fLLL6tatWr2z1u3blX79u3l7+8vm82mVq1a6dtvv72alwkAl0RyA5jMRx99pDp16qh27drq16+f3nnnHV18Vudnn32m++67TxEREfruu++UkJCgJk2aSJKWLFmiypUra/LkyUpNTVVqamqRz3nq1ClFRUXp66+/1qZNm3TLLbcoIiJCp06duirXCACXc5OrAwDgXLNnz1a/fv0kSR07dlRmZqYSExPVunVrPfvss+rdu7cmTZpk79+gQQNJUvny5eXu7q6yZcsqKCioWOds06aNw+c333xTvr6+SkxMVJcuXa7wigCgeKjcACaSnJysLVu2qE+fPpKkm266Sb169dLs2bMlSTt27FDbtm2dft709HQNGTJEt9xyi2w2m3x8fJSdna2UlBSnnwsA/g6VG8BEZs+erdzcXFWqVMneZhiGrFar/vvf/8rLy6vYY7q5uemvr6C7cOGCw+eoqCgdO3ZMr7zyioKDg2W1WhUWFqbz58+X7EIA4ApQuQFMIjc3V++++66mTZumHTt22LedO3eqUqVKev/991W/fn0lJCRccgxPT0/l5eU5tFWoUEFpaWkOCc6OHTsc+nzzzTd67LHHFBERobp168pqtero0aNOvT4AKCoqN4BJrFixQidOnNDgwYNls9kc9kVGRmr27Nl64YUX1LZtW9WoUUO9e/dWbm6uPv/8c40bN07SH8+52bBhg3r37i2r1Sp/f3+1bt1aR44c0dSpU9W9e3etXLlSX3zxhXx8fOzj33LLLZo/f74aN26srKwsjRkzpkRVIgBwBio3gEnMnj1b7dq1K5DYSH8kN9u2bVP58uW1aNEiffrpp2rYsKHatGmjLVu22PtNnjxZv/zyi2rUqKEKFSpIkkJCQvT666/rtddeU4MGDbRlyxaNHj26wLlPnDih22+/Xf3799djjz2mgICAq3vBAHAJFuOvk+kAAAA3MCo3AADAVEhuAACAqZDcAAAAUyG5AQAApkJyAwAATIXkBgAAmArJDQAAMBWSGwAAYCokNwAAwFRIbgAAgKmQ3AAAAFMhuQEAAKbyf+tSTXDArMp3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mod11.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-01T15:45:44.080318Z",
          "iopub.execute_input": "2024-03-01T15:45:44.080681Z",
          "iopub.status.idle": "2024-03-01T15:45:44.551284Z",
          "shell.execute_reply.started": "2024-03-01T15:45:44.080652Z",
          "shell.execute_reply": "2024-03-01T15:45:44.550276Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzQMofnd7zeT",
        "outputId": "2df2f16d-3b4d-45aa-c2de-1290e87b1924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "def submit(folder_path):\n",
        "    model_prediction=[]\n",
        "    model=load_model('mod11.h5')\n",
        "    for filename in os.listdir(folder_path):\n",
        "        video_file = os.path.join(folder_path, filename)\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        frames = []\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frames.append(frame)\n",
        "\n",
        "        # Extract features using pre-trained model\n",
        "        prediction_images = []\n",
        "        for img in frames:\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            img = image.img_to_array(img)\n",
        "            img = img / 255\n",
        "            prediction_images.append(img)\n",
        "\n",
        "        # Convert all the frames for a test video into numpy array\n",
        "        prediction_images = np.array(prediction_images)\n",
        "\n",
        "        # Extract features using pre-trained model\n",
        "        prediction_images = base_model.predict(prediction_images)\n",
        "\n",
        "        # Convert features into one-dimensional array\n",
        "        prediction_images = prediction_images.reshape(prediction_images.shape[0], 7 * 7 * 512)\n",
        "\n",
        "        # Predict tags for each array\n",
        "        predictions = model.predict(prediction_images)\n",
        "\n",
        "        # Append the mode of predictions in predict list to assign the tag to the video\n",
        "        # Assuming 0 corresponds to \"not shoplift\" and 1 corresponds to \"shoplift\"\n",
        "        # Use majority voting to determine the predicted class label\n",
        "        predicted_class = \"1\" if np.mean(predictions) > 0.5 else \"0\"\n",
        "        model_prediction.append(predicted_class)\n",
        "\n",
        "    return model_prediction\n",
        "\n",
        "folder='my_folder'\n",
        "predictions = submit(folder)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3lYslEoA_Be",
        "outputId": "ff869444-8983-442d-996d-3d214c894610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 3s 323ms/step\n",
            "11/11 [==============================] - 1s 21ms/step\n",
            "10/10 [==============================] - 4s 445ms/step\n",
            "10/10 [==============================] - 0s 18ms/step\n",
            "9/9 [==============================] - 6s 788ms/step\n",
            "9/9 [==============================] - 0s 33ms/step\n",
            "['0', '1', '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the name of the file and the name of the folder\n",
        "file_name = \"DCSASS Dataset/Shoplifting/Shoplifting001_x264.mp4/Shoplifting001_x264_14.mp4\"\n",
        "folder_name = \"Shoplifting1\"\n",
        "\n",
        "# Specify the source path of the file\n",
        "source_path = \"/content/\" + file_name\n",
        "\n",
        "# Specify the destination path of the folder\n",
        "destination_path = \"/content/\" + folder_name + \"/\" + file_name\n",
        "\n",
        "# Copy the file to the specified folder\n",
        "shutil.move(source_path, destination_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "2Zgnmo0HBgNn",
        "outputId": "cd5b745d-637f-4ed0-bc5a-32ed4cece0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Shoplifting1/DCSASS Dataset/Shoplifting/Shoplifting001_x264.mp4/Shoplifting001_x264_14.mp4'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/DCSASS Dataset/Shoplifting/Shoplifting001_x264.mp4/Shoplifting001_x264_14.mp4' -> '/content/Shoplifting1/DCSASS Dataset/Shoplifting/Shoplifting001_x264.mp4/Shoplifting001_x264_14.mp4'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1f130e6b8b8d>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Copy the file to the specified folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                     \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Shoplifting1/DCSASS Dataset/Shoplifting/Shoplifting001_x264.mp4/Shoplifting001_x264_14.mp4'"
          ]
        }
      ]
    }
  ]
}